{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型适应性测试\n",
    "\n",
    "## 导入依赖库，传入模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class Args:\n",
    "    def __init__(self, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "args = Args(\n",
    "    task_name=\"long_term_forecast\",\n",
    "    is_training=1,\n",
    "    root_path=\"./dataset/Gas/\",\n",
    "    data_path=\"134312_data.csv\",\n",
    "    model_id=\"Gas_96_96\",\n",
    "    model=\"DLinear\",\n",
    "    data=\"Gas\",\n",
    "    features=\"M\",\n",
    "    target=\"value\",\n",
    "    seq_len=96,\n",
    "    label_len=48,\n",
    "    pred_len=96,\n",
    "    e_layers=2,\n",
    "    d_layers=1,\n",
    "    d_model=512,\n",
    "    n_heads=8,\n",
    "    factor=3,\n",
    "    enc_in=8,\n",
    "    dec_in=8,\n",
    "    c_out=8,\n",
    "    des=\"Exp\",\n",
    "    itr=1,\n",
    "    use_gpu=True,\n",
    "    gpu=\"0\",\n",
    "    device=\"2,3\",\n",
    "    loss=\"MSE\",\n",
    "    distil=True,\n",
    "    embed=\"timeF\",\n",
    "    seed=0,\n",
    "    local_rank=0,\n",
    "    d_ff=2048,\n",
    "    adaptation=False,\n",
    "    noiseness=False,\n",
    "    periodicity=False,\n",
    "    distribution=False,\n",
    "    anomaly=False,\n",
    "    moving_avg=25,\n",
    "    freq=\"h\",\n",
    "    checkpoints=\"./checkpoints/\",\n",
    "    feature=\"M\",\n",
    "    inverse=False,\n",
    "    seasonal_patterns=\"Monthly\",\n",
    "    num_workers=10,\n",
    "    batch_size=32,\n",
    "    use_ims=False,\n",
    "    use_weight_decay=0,\n",
    "    learning_rate=0.0001,\n",
    "    use_amp=False,\n",
    "    output_attention=None,\n",
    ")\n",
    "\n",
    "args.output_len = args.pred_len\n",
    "args.output_len_list = [args.output_len]\n",
    "\n",
    "fix_seed = args.seed\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)\n",
    "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "\n",
    "ii = 0\n",
    "setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}'.format(\n",
    "    args.task_name,\n",
    "    args.model_id,\n",
    "    args.model,\n",
    "    args.data,\n",
    "    args.features,\n",
    "    args.seq_len,\n",
    "    args.label_len,\n",
    "    args.pred_len,\n",
    "    args.d_model,\n",
    "    args.n_heads,\n",
    "    args.e_layers,\n",
    "    args.d_layers,\n",
    "    args.d_ff,\n",
    "    args.factor,\n",
    "    args.embed,\n",
    "    args.distil,\n",
    "    args.des,\n",
    "    ii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 噪声适应性\n",
    "* `add_gaussian_white_noise`：添加高斯白噪声\n",
    "* `add_red_noise`：添加红噪声"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_white_noise(tensor, mean=0.0, std=1.0, rd=1):\n",
    "    noise = torch.normal(mean, std * rd, tensor.size())\n",
    "    return tensor + noise\n",
    "\n",
    "def add_red_noise(tensor, alpha=0.5, rd=1):\n",
    "    alpha = alpha * rd\n",
    "    batch_size, seq_len, feature_num = tensor.size()\n",
    "    red_noise = torch.zeros_like(tensor)\n",
    "    \n",
    "    red_noise[:, 0, :] = torch.normal(0, 1, (batch_size, feature_num))\n",
    "    \n",
    "    for i in range(1, seq_len):\n",
    "        red_noise[:, i, :] = alpha * red_noise[:, i-1, :] + torch.normal(0, (1 - alpha**2)**0.5, (batch_size, feature_num))\n",
    "    \n",
    "    return tensor + red_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 周期性适应性\n",
    "* `phase_shift`：添加相位偏移\n",
    "* `period_scale`：添加周期性缩放"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase_shift(tensor, shift=None, rd=1):\n",
    "    batchsize, seqlen, featurenum = tensor.shape\n",
    "    shift = int(rd * seqlen * 0.2)\n",
    "    if shift >= 0:\n",
    "        shifted_tensor = torch.cat([tensor[:, shift:, :], tensor[:, :shift, :]], dim=1)\n",
    "    else:\n",
    "        shift = abs(shift)\n",
    "        shifted_tensor = torch.cat([tensor[:, seqlen-shift:, :], tensor[:, :seqlen-shift, :]], dim=1)\n",
    "    return shifted_tensor\n",
    "\n",
    "def period_scale(tensor, scale=2.0, rd=1):\n",
    "    batchsize, seqlen, featurenum = tensor.shape\n",
    "\n",
    "    new_seqlen = int(seqlen * scale * rd)  # 使用 rd 调整缩放比例\n",
    "    \n",
    "    # 创建时间轴的坐标范围为 0 到 1，以保持周期性\n",
    "    time_axis = torch.linspace(0, 1, steps=seqlen, device=tensor.device, dtype=tensor.dtype)\n",
    "    new_time_axis = torch.linspace(0, 1, steps=new_seqlen, device=tensor.device, dtype=tensor.dtype)\n",
    "    \n",
    "    # 为每个特征创建网格\n",
    "    y_axis = torch.arange(featurenum, device=tensor.device, dtype=tensor.dtype)\n",
    "    grid = torch.stack(torch.meshgrid(time_axis, y_axis, indexing='ij'), dim=-1)  # (seqlen, featurenum, 2)\n",
    "    grid = grid.unsqueeze(0).repeat(batchsize, 1, 1, 1)  # (batchsize, seqlen, featurenum, 2)\n",
    "    \n",
    "    # 调整网格到新的序列长度\n",
    "    new_grid = torch.stack(torch.meshgrid(new_time_axis, y_axis, indexing='ij'), dim=-1)  # (new_seqlen, featurenum, 2)\n",
    "    new_grid = new_grid.unsqueeze(0).repeat(batchsize, 1, 1, 1)  # (batchsize, new_seqlen, featurenum, 2)\n",
    "    \n",
    "    # 使用 grid_sample 进行采样\n",
    "    tensor = tensor.unsqueeze(1)  # (batchsize, 1, seqlen, featurenum)\n",
    "    tensor = torch.nn.functional.grid_sample(tensor, new_grid, mode='bilinear', align_corners=True).squeeze(1)  # (batchsize, new_seqlen, featurenum)\n",
    "    \n",
    "    if new_seqlen > seqlen:\n",
    "        tensor = tensor[:, :seqlen, :]\n",
    "    else:\n",
    "        pad_size = seqlen - new_seqlen\n",
    "        tensor = torch.cat([tensor, tensor[:, :pad_size, :]], dim=1)\n",
    "\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据分布适应性\n",
    "* `global_mean_shift`：添加全局均值偏移\n",
    "* `data_range_scaling`：添加数据范围缩放"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_mean_shift(tensor, shift_amount=1, rd=1):\n",
    "    if isinstance(shift_amount, (int, float)):\n",
    "        shift_amount = tensor.new_full((1, 1, tensor.size(2)), shift_amount)\n",
    "    elif isinstance(shift_amount, torch.Tensor):\n",
    "        assert shift_amount.size(0) == tensor.size(2), \"the length of shift_amount must be the same as feature_num\"\n",
    "    else:\n",
    "        raise ValueError(\"shift_amount must be a scalar or a vector of the same length as feature_num\")\n",
    "    \n",
    "    return tensor + shift_amount * rd\n",
    "\n",
    "def data_range_scaling(tensor, scale_factor=0.9, rd=1):\n",
    "    if isinstance(scale_factor, (int, float)):\n",
    "        scale_factor = tensor.new_full((1, 1, tensor.size(2)), scale_factor)\n",
    "    elif isinstance(scale_factor, torch.Tensor):\n",
    "        assert scale_factor.size(0) == tensor.size(2), \"the length of scale_factor must be the same as feature_num\"\n",
    "    else:\n",
    "        raise ValueError(\"scale_factor must be a scalar or a vector of the same length as feature_num\")\n",
    "    \n",
    "    return tensor * scale_factor * rd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据异常适应性\n",
    "* `add_missing_values`：添加缺失值\n",
    "* `add_outlier_values`：添加异常极大的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_values(tensor, missing_rate=0.05, rd=1):\n",
    "    mask = torch.rand(tensor.size()) < missing_rate * rd\n",
    "    tensor[mask] = 0.0\n",
    "    return tensor\n",
    "\n",
    "def add_outlier_values(tensor, outlier_rate=0.05, magnitude=20, rd=1):\n",
    "    mask = torch.rand(tensor.size()) < outlier_rate * rd\n",
    "    # 生成异常值，并确保异常值的类型与 tensor 相同\n",
    "    outliers = magnitude * torch.randn(*tensor.size()).to(tensor.dtype)\n",
    "    tensor[mask] = outliers[mask]\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 根据不同任务选择对应的适应性函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptivity(x, i, args, rd=1):\n",
    "    adp_type = \"\"\n",
    "    if i % 2 == 0:\n",
    "        if args.noiseness:\n",
    "            trans_x = add_gaussian_white_noise(x, rd)\n",
    "            adp_type = \"noiseness\"\n",
    "        if args.periodicity:\n",
    "            trans_x = phase_shift(x, rd)\n",
    "            adp_type = \"periodicity\"\n",
    "        if args.distribution:\n",
    "            trans_x = global_mean_shift(x, rd)\n",
    "            adp_type = \"distribution\"\n",
    "        if args.anomaly:\n",
    "            trans_x = add_missing_values(x, rd)\n",
    "            adp_type = \"anomaly\"\n",
    "    else:\n",
    "        if args.noiseness:\n",
    "            trans_x = add_red_noise(x, rd)\n",
    "            adp_type = \"noiseness\"\n",
    "        if args.periodicity:\n",
    "            trans_x = period_scale(x, rd)\n",
    "            adp_type = \"periodicity\"\n",
    "        if args.distribution:\n",
    "            trans_x = data_range_scaling(x, rd)\n",
    "            adp_type = \"distribution\"\n",
    "        if args.anomaly:\n",
    "            trans_x = add_outlier_values(x, rd)\n",
    "            adp_type = \"anomaly\"\n",
    "    return trans_x, adp_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推理部分\n",
    "* **适应性指标计算**(`adaptation_test`)：将原测试集数据替换为适应性变换后数据，输入给模型进行推理，预测结果与ground truth比较，计算MSE的平均值，得到各项适应性指标。指标结果越小，表明适应性越好。\n",
    "* **适应性指标验证**(`adaptation_varify`)：模拟真实数据使用环境，将原测试集数据添加随机强度的适应性变换，得到模拟真实测试集，输入给模型进行推理，预测结果与ground truth比较，计算MSE的平均值，作为适应性指标验证结果。适应性指标与真实适应性指标验证结果呈正相关，适应性指标验证成功。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tools import *\n",
    "from data_provider.data_factory import data_provider\n",
    "from utils.metrics import metric\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from models import DLinear\n",
    "\n",
    "class Exp(object):\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = self._build_model().to(self.device)\n",
    "        \n",
    "    def _build_model(self):\n",
    "        model = DLinear.Model(self.args)\n",
    "        return model\n",
    "\n",
    "    def _get_data(self, flag):\n",
    "        data_set, data_loader = data_provider(self.args, flag)\n",
    "        return data_set, data_loader\n",
    "\n",
    "    def _select_optimizer(self):\n",
    "        if self.args.use_weight_decay:\n",
    "            model_optim = optim.Adam(self.model.parameters(), lr=self.args.learning_rate,\n",
    "                                     weight_decay=self.args.weight_decay)\n",
    "        else:\n",
    "            model_optim = optim.Adam(self.model.parameters(), lr=self.args.learning_rate)\n",
    "        return model_optim\n",
    "\n",
    "    def _select_criterion(self):\n",
    "        criterion = nn.MSELoss()\n",
    "        return criterion\n",
    "\n",
    "    # 适应性测试，计算适应性指标\n",
    "    def adaptation_test(self, setting):\n",
    "        print('Model parameters: ', sum(param.numel() for param in self.model.parameters()))\n",
    "        attns = []\n",
    "        folder_path = './test_results/' + setting + '/' + self.args.data_path + '/' + f'{self.args.output_len}/'\n",
    "        if not os.path.exists(folder_path) and int(os.environ.get(\"LOCAL_RANK\", \"0\")) == 0:\n",
    "            os.makedirs(folder_path)\n",
    "        self.model.eval()\n",
    "        if self.args.output_len_list is None:\n",
    "            self.args.output_len_list = [self.args.output_len]\n",
    "\n",
    "        trues_list = [[] for _ in range(len(self.args.output_len_list))]\n",
    "        trans_list = [[] for _ in range(len(self.args.output_len_list))]\n",
    "        self.args.output_len_list.sort()\n",
    "        adp_type = \"\"\n",
    "        \n",
    "        # pic_path = './adapt/' + setting + '/' + self.args.data_path + '/'\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for output_ptr in range(len(self.args.output_len_list)):\n",
    "                self.args.output_len = self.args.output_len_list[output_ptr]\n",
    "                test_data, test_loader = data_provider(self.args, flag='test')\n",
    "                \n",
    "                for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(test_loader):\n",
    "                    # 适应性数据替换\n",
    "                    if i % 2 == 0:\n",
    "                        trans_batch_x, adp_type = adaptivity(batch_x, i, self.args, rd=1)\n",
    "                    else:\n",
    "                        trans_batch_x, adp_type = adaptivity(batch_x, i, self.args, rd=1)\n",
    "                    # 推理\n",
    "                    trans_pred, true = self.adaptation_forecast(test_data, trans_batch_x, batch_y, batch_x_mark, batch_y_mark)\n",
    "                \n",
    "                    trues_list[output_ptr].append(true)\n",
    "                    trans_list[output_ptr].append(trans_pred)\n",
    "\n",
    "        if self.args.output_len_list is not None:\n",
    "            for i in range(len(trues_list)):\n",
    "                true = trues_list[i]\n",
    "                trans_preds = trans_list[i]\n",
    "                true = torch.cat(true, dim=0).numpy()\n",
    "                trans_preds = torch.cat(trans_preds, dim=0).numpy()\n",
    "                \n",
    "                mae, mse, rmse, mape, mspe = metric(true, trans_preds)\n",
    "                print(f\"output_len: {self.args.output_len_list[i]}\")\n",
    "                print('{} adaptation:{}'.format(adp_type, mae))\n",
    "        \n",
    "        return\n",
    "\n",
    "    def adaptation_forecast(self, test_data, batch_x, batch_y, batch_x_mark, batch_y_mark):\n",
    "        batch_x = batch_x.float().to(self.device)\n",
    "        batch_y = batch_y.float().to(self.device)\n",
    "        batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "        batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "        dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n",
    "        dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "        inference_steps = self.args.output_len // self.args.pred_len\n",
    "        dis = self.args.output_len - inference_steps * self.args.pred_len\n",
    "        if dis != 0:\n",
    "            inference_steps += 1\n",
    "        pred_y = []\n",
    "        for j in range(inference_steps):\n",
    "            if len(pred_y) != 0:\n",
    "                batch_x = torch.cat([batch_x[:, self.args.pred_len:, :], pred_y[-1]], dim=1)\n",
    "                tmp = batch_y_mark[:, j - 1:j, :]\n",
    "                batch_x_mark = torch.cat([batch_x_mark[:, 1:, :], tmp], dim=1)\n",
    "\n",
    "            outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "            f_dim = -1 if self.args.features == 'MS' else 0\n",
    "            pred_y.append(outputs[:, -self.args.pred_len:, :])\n",
    "        pred_y = torch.cat(pred_y, dim=1)\n",
    "\n",
    "        if dis != 0:\n",
    "            pred_y = pred_y[:, :-dis, :]\n",
    "\n",
    "        if self.args.use_ims:\n",
    "            batch_y = batch_y[:, self.args.label_len:self.args.label_len + self.args.output_len, :].to(\n",
    "                self.device)\n",
    "        else:\n",
    "            batch_y = batch_y[:, :self.args.output_len, :].to(self.device)\n",
    "\n",
    "        outputs = pred_y.detach().cpu()\n",
    "        batch_y = batch_y.detach().cpu()\n",
    "            \n",
    "        if test_data.scale and self.args.inverse:\n",
    "            shape = outputs.shape\n",
    "            outputs = test_data.inverse_transform(outputs.squeeze(0)).reshape(shape)\n",
    "            batch_y = test_data.inverse_transform(batch_y.squeeze(0)).reshape(shape)\n",
    "\n",
    "        outputs = outputs[:, :, f_dim:]\n",
    "        batch_y = batch_y[:, :, f_dim:]\n",
    "\n",
    "        pred = outputs\n",
    "        true = batch_y\n",
    "        \n",
    "        return pred, true\n",
    "\n",
    "    # 验证适应性指标\n",
    "    def adaptation_varify(self, setting):\n",
    "        attns = []\n",
    "        folder_path = './test_results/' + setting + '/' + self.args.data_path + '/' + f'{self.args.output_len}/'\n",
    "        if not os.path.exists(folder_path) and int(os.environ.get(\"LOCAL_RANK\", \"0\")) == 0:\n",
    "            os.makedirs(folder_path)\n",
    "        self.model.eval()\n",
    "        if self.args.output_len_list is None:\n",
    "            self.args.output_len_list = [self.args.output_len]\n",
    "\n",
    "        trues_list = [[] for _ in range(len(self.args.output_len_list))]\n",
    "        trans_list = [[] for _ in range(len(self.args.output_len_list))]\n",
    "        self.args.output_len_list.sort()\n",
    "        adp_type = \"\"\n",
    "        \n",
    "        # pic_path = './adapt/' + setting + '/' + self.args.data_path + '/'\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for output_ptr in range(len(self.args.output_len_list)):\n",
    "                self.args.output_len = self.args.output_len_list[output_ptr]\n",
    "                test_data, test_loader = data_provider(self.args, flag='test')\n",
    "                \n",
    "                for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(test_loader):\n",
    "                    if i % 50 == 0 or i % 51 == 0:\n",
    "                        # 生成系统随机数\n",
    "                        random_bytes = os.urandom(4)\n",
    "                        random_int = int.from_bytes(random_bytes, 'big')\n",
    "                        random_float = (random_int >> 11) / (1 << 23) + 0.5\n",
    "                        # 适应性数据替换\n",
    "                        trans_batch_x, adp_type = adaptivity(batch_x, i, self.args, rd=random_float)\n",
    "                    # 推理\n",
    "                    trans_pred, true = self.adaptation_forecast(test_data, trans_batch_x, batch_y, batch_x_mark, batch_y_mark)\n",
    "                    \n",
    "                    trues_list[output_ptr].append(true)\n",
    "                    trans_list[output_ptr].append(trans_pred)\n",
    "\n",
    "        if self.args.output_len_list is not None:\n",
    "            for i in range(len(trues_list)):\n",
    "                true = trues_list[i]\n",
    "                trans_preds = trans_list[i]\n",
    "                true = torch.cat(true, dim=0).numpy()\n",
    "                trans_preds = torch.cat(trans_preds, dim=0).numpy()\n",
    "                \n",
    "                mae, mse, rmse, mape, mspe = metric(true, trans_preds)\n",
    "                print('{} adaptation verify:{}'.format(adp_type, mae))\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def fgsm_attack(self, data, epsilon, data_grad):\n",
    "        # Collect the element-wise sign of the data gradient\n",
    "        sign_data_grad = data_grad.sign()\n",
    "        # Create the perturbed image by adjusting each pixel of the input image\n",
    "        perturbed_data = data + epsilon*sign_data_grad\n",
    "        # Adding clipping to maintain [0,1] range\n",
    "        # perturbed_data = torch.clamp(perturbed_data, 0, 1)\n",
    "        # Return the perturbed image\n",
    "        return perturbed_data\n",
    "\n",
    "    def adversarial_attack(self, setting, test=0):\n",
    "        test_data, test_loader = self._get_data(flag='test')\n",
    "        if test:\n",
    "            if self.args.ckpt_path != '':\n",
    "                if self.args.ckpt_path == 'random':\n",
    "                    print('loading model randomly')\n",
    "                else:\n",
    "                    print('loading model: ', self.args.ckpt_path)\n",
    "                    if self.args.ckpt_path.endswith('.pth'):\n",
    "                        self.model.load_state_dict(torch.load(self.args.ckpt_path))\n",
    "                    else:\n",
    "                        raise NotImplementedError\n",
    "            else:\n",
    "                print('loading model with settings: {}'.format(setting))\n",
    "                self.model.load_state_dict(torch.load(os.path.join('./checkpoints/' + setting, 'checkpoint.pth')))\n",
    "            \n",
    "        preds = []\n",
    "        trues = []\n",
    "        adv_preds = []\n",
    "        folder_path = './test_results/' + setting + '/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "        self.model.eval()\n",
    "        model_optim = self._select_optimizer()\n",
    "        criterion = self._select_criterion()\n",
    "        \n",
    "        for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(test_loader):\n",
    "            model_optim.zero_grad()\n",
    "            batch_x = batch_x.float().to(self.device)\n",
    "            batch_y = batch_y.float().to(self.device)\n",
    "            batch_x.requires_grad= True\n",
    "\n",
    "            batch_x_mark = batch_x_mark.float().to(self.device)\n",
    "            batch_y_mark = batch_y_mark.float().to(self.device)\n",
    "\n",
    "            # decoder input\n",
    "            dec_inp = torch.zeros_like(batch_y[:, -self.args.pred_len:, :]).float()\n",
    "            dec_inp = torch.cat([batch_y[:, :self.args.label_len, :], dec_inp], dim=1).float().to(self.device)\n",
    "            # encoder - decoder\n",
    "            if self.args.use_amp:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    if self.args.output_attention:\n",
    "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                    else:\n",
    "                        outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "            else:\n",
    "                if self.args.output_attention:\n",
    "                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                else:\n",
    "                    outputs = self.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "            f_dim = -1 if self.args.features == 'MS' else 0\n",
    "            outputs = outputs[:, -self.args.pred_len:, :]\n",
    "            batch_y = batch_y[:, -self.args.pred_len:, :].to(self.device)\n",
    "            loss = criterion(outputs,batch_y)\n",
    "            loss.backward()\n",
    "            data_grad = batch_x.grad.data\n",
    "            if i % 2 == 0:\n",
    "                adv_batch_x = self.fgsm_attack(batch_x, 0.1, data_grad)\n",
    "            else:\n",
    "                adv_batch_x = self.fgsm_attack(batch_x, 0.07, data_grad)\n",
    "\n",
    "            if self.args.use_amp:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    if self.args.output_attention:\n",
    "                        adv_outputs = self.model(adv_batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                    else:\n",
    "                        adv_outputs = self.model(adv_batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "            else:\n",
    "                if self.args.output_attention:\n",
    "                    adv_outputs = self.model(adv_batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                else:\n",
    "                    adv_outputs = self.model(adv_batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "            f_dim = -1 if self.args.features == 'MS' else 0\n",
    "            adv_outputs = adv_outputs[:, -self.args.pred_len:, :]\n",
    "\n",
    "            outputs = outputs.detach().cpu().numpy()\n",
    "            adv_outputs = adv_outputs.detach().cpu().numpy()\n",
    "            batch_y = batch_y.detach().cpu().numpy()\n",
    "\n",
    "            if ',' in self.args.data:\n",
    "                if test_data.datasets[0].scale and self.args.inverse:\n",
    "                    shape = outputs.shape\n",
    "                    outputs = test_data.inverse_transform(outputs.squeeze(0)).reshape(shape)\n",
    "                    batch_y = test_data.inverse_transform(batch_y.squeeze(0)).reshape(shape)\n",
    "            else:\n",
    "                if test_data.scale and self.args.inverse:\n",
    "                    shape = outputs.shape\n",
    "                    outputs = test_data.inverse_transform(outputs.reshape(shape[0] * shape[1], -1)).reshape(shape)\n",
    "                    batch_y = test_data.inverse_transform(batch_y.reshape(shape[0] * shape[1], -1)).reshape(shape)\n",
    "                    adv_outputs = test_data.inverse_transform(adv_outputs.reshape(shape[0] * shape[1], -1)).reshape(shape)\n",
    "\n",
    "            outputs = outputs[:, :, f_dim:]\n",
    "            batch_y = batch_y[:, :, f_dim:]\n",
    "            adv_outputs = adv_outputs[:, :, f_dim:]\n",
    "\n",
    "            pred = outputs\n",
    "            true = batch_y\n",
    "            adv_pred = adv_outputs\n",
    "\n",
    "            preds.append(pred)\n",
    "            trues.append(true)\n",
    "            adv_preds.append(adv_pred)\n",
    "\n",
    "            if i % 5 == 0:\n",
    "                input = batch_x.detach().cpu().numpy()\n",
    "                adv_input = adv_batch_x.detach().cpu().numpy()\n",
    "                if ',' in self.args.data:\n",
    "                    if test_data.datasets[0].scale and self.args.inverse:\n",
    "                        shape = input.shape\n",
    "                        input = test_data.inverse_transform(input.squeeze(0)).reshape(shape)\n",
    "                else:\n",
    "                    if test_data.scale and self.args.inverse:\n",
    "                        shape = input.shape\n",
    "                        input = test_data.inverse_transform(input.reshape(shape[0] * shape[1], -1)).reshape(shape)\n",
    "                        adv_input = test_data.inverse_transform(adv_input.reshape(shape[0] * shape[1], -1)).reshape(shape)\n",
    "                # gt = np.concatenate((input[0, :, -1], true[0, :, -1]), axis=0)\n",
    "                # pd = np.concatenate((input[0, :, -1], pred[0, :, -1]), axis=0)\n",
    "                # adv = np.concatenate((adv_input[0, :, -1], adv_pred[0, :, -1]), axis=0)\n",
    "                # visual(gt, pd, adv, os.path.join(folder_path, str(i) + '.pdf'))\n",
    "\n",
    "        preds = np.array(preds)\n",
    "        trues = np.array(trues)\n",
    "        adv_preds = np.array(adv_preds)\n",
    "        # print('test shape:', preds.shape, trues.shape, adv_preds.shape)\n",
    "        preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
    "        trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n",
    "        adv_preds = adv_preds.reshape(-1, adv_preds.shape[-2], adv_preds.shape[-1])\n",
    "        # print('test shape:', preds.shape, trues.shape, adv_preds.shape)\n",
    "\n",
    "        # result save\n",
    "        folder_path = './results/' + setting + '/'\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "        mae, mse, rmse, mape, mspe = metric(preds, trues)\n",
    "        adv_mae, adv_mse, adv_rmse, adv_mape, adv_mspe = metric(adv_preds, trues)\n",
    "        print(f\"output_len: {self.args.output_len}\")\n",
    "        print('Before attacking: mse:{}, mae:{}'.format(mse, mae))\n",
    "        print('After attacking: mse:{}, mae:{}'.format(adv_mse, adv_mae))\n",
    "        print(\"Adversary adaptation:{}\".format(adv_mae))\n",
    "\n",
    "        f = open(\"result_adaptation_test_forecast.txt\", 'a')\n",
    "        f.write(setting + \"  \\n\")\n",
    "        f.write('Before attacking: mse:{}, mae:{}'.format(mse, mae))\n",
    "        f.write('\\n')\n",
    "        f.write('After attacking: mse:{}, mae:{}'.format(adv_mse, adv_mae))\n",
    "        f.write('\\n')\n",
    "        f.write('\\n')\n",
    "        f.close()\n",
    "\n",
    "        # np.save(folder_path + 'metrics.npy', np.array([mae, mse, rmse, mape, mspe]))\n",
    "        # np.save(folder_path + 'pred.npy', preds)\n",
    "        # np.save(folder_path + 'true.npy', trues)\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 噪声适应性指标计算及验证\n",
    "* 调用适应性指标计算接口`adaptation_test`，计算指标\n",
    "* 调用适应性指标验证接口`adaptation_varify`，验证指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters:  18624\n",
      "test 1905\n",
      "output_len: 96\n",
      "noiseness adaptation:1.177431583404541\n",
      "test 1905\n",
      "noiseness adaptation verify:1.008675217628479\n"
     ]
    }
   ],
   "source": [
    "args.adaptation = True\n",
    "args.noiseness = True\n",
    "exp = Exp(args)\n",
    "exp.adaptation_test(setting)\n",
    "exp.adaptation_varify(setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 周期性适应性指标计算及验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters:  18624\n",
      "test 1905\n",
      "output_len: 96\n",
      "periodicity adaptation:0.9080523252487183\n",
      "test 1905\n",
      "periodicity adaptation verify:1.0128289461135864\n"
     ]
    }
   ],
   "source": [
    "args.adaptation = True\n",
    "args.noiseness = False\n",
    "args.periodicity = True\n",
    "exp = Exp(args)\n",
    "exp.adaptation_test(setting)\n",
    "exp.adaptation_varify(setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据分布适应性指标计算及验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters:  18624\n",
      "test 1905\n",
      "output_len: 96\n",
      "distribution adaptation:1.0089056491851807\n",
      "test 1905\n",
      "distribution adaptation verify:0.9720181226730347\n"
     ]
    }
   ],
   "source": [
    "args.adaptation = True\n",
    "args.periodicity = False\n",
    "args.distribution = True\n",
    "exp = Exp(args)\n",
    "exp.adaptation_test(setting)\n",
    "exp.adaptation_varify(setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据异常适应性指标计算及验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters:  18624\n",
      "test 1905\n",
      "output_len: 96\n",
      "anomaly adaptation:1.326231837272644\n",
      "test 1905\n",
      "anomaly adaptation verify:1.110696792602539\n"
     ]
    }
   ],
   "source": [
    "args.adaptation = True\n",
    "args.distribution = False\n",
    "args.anomaly = True\n",
    "exp = Exp(args)\n",
    "exp.adaptation_test(setting)\n",
    "exp.adaptation_varify(setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对抗样本适应性指标计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 1905\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Args' object has no attribute 'output_attention'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m args\u001b[38;5;241m.\u001b[39madversary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      4\u001b[0m exp \u001b[38;5;241m=\u001b[39m Exp(args)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madversarial_attack\u001b[49m\u001b[43m(\u001b[49m\u001b[43msetting\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 237\u001b[0m, in \u001b[0;36mExp.adversarial_attack\u001b[0;34m(self, setting, test)\u001b[0m\n\u001b[1;32m    235\u001b[0m             outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_attention\u001b[49m:\n\u001b[1;32m    238\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(batch_x, batch_x_mark, dec_inp, batch_y_mark)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Args' object has no attribute 'output_attention'"
     ]
    }
   ],
   "source": [
    "args.adaptation = True\n",
    "args.anomaly = False\n",
    "args.adversary = True\n",
    "exp = Exp(args)\n",
    "exp.adversarial_attack(setting)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ljf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
